{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Captum Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from captum.insights import AttributionVisualizer, Batch\n",
    "from captum.insights.attr_vis.features import ImageFeature\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from melanoma_cnn_efficientnet import Net, CustomDataset, train_test_split\n",
    "\n",
    "# Setting up GPU for processing or CPU if GPU isn't available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "testing_transforms = transforms.Compose([transforms.Resize(256),\n",
    "                                        transforms.CenterCrop(256),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                             [0.229, 0.224, 0.225])])\n",
    "                              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions for classification classes and pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes():\n",
    "    classes = [\n",
    "        \"Non-melanoma\",\n",
    "        \"Melanoma\", \n",
    "    ]\n",
    "    return classes\n",
    "\n",
    "def get_pretrained_model():\n",
    "    arch = EfficientNet.from_pretrained('efficientnet-b2')\n",
    "    model = Net(arch=arch)  \n",
    "    # summary(model, (3, 256, 256), device='cpu')\n",
    "    model.load_state_dict(torch.load('/workspace/stylegan2-ada-pytorch/CNN_trainings/melanoma_model_0_0.9225_16_12_train_reals+15melanoma.pth'))\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "def baseline_func(input):\n",
    "    return input * 0 # +256\n",
    "\n",
    "\n",
    "def formatted_data_iter():\n",
    "    # ISIC dataset\n",
    "    df = pd.read_csv('/workspace/melanoma_isic_dataset/train_concat.csv') \n",
    "    train_img_dir = os.path.join('/workspace/melanoma_isic_dataset/train/train/')\n",
    "    \n",
    "    train_split, valid_split = train_test_split (df, stratify=df.target, test_size = 0.20, random_state=42) \n",
    "    validation_df=pd.DataFrame(valid_split)\n",
    "    validation_df['image_name'] = [os.path.join(train_img_dir, validation_df.iloc[index]['image_name'] + '.jpg') for index in range(len(validation_df))]\n",
    "    testing_dataset = CustomDataset(df = validation_df, train = True, transforms = testing_transforms ) \n",
    "    dataloader = torch.utils.data.DataLoader(testing_dataset, batch_size=16, shuffle = False)         \n",
    "    while True:\n",
    "        images, labels = next(dataloader)\n",
    "        yield Batch(inputs=images, labels=labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the visualizer and render inside notebook for interactive debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b2\n"
     ]
    }
   ],
   "source": [
    "model = get_pretrained_model()\n",
    "visualizer = AttributionVisualizer(\n",
    "    models=[model],\n",
    "    score_func=lambda o: torch.nn.functional.softmax(o, 1),\n",
    "    classes=get_classes(),\n",
    "    features=[\n",
    "        ImageFeature(\n",
    "            \"Photo\",\n",
    "            baseline_transforms=[baseline_func],\n",
    "            input_transforms=[testing_transforms],\n",
    "        )\n",
    "    ],\n",
    "    dataset=formatted_data_iter(),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ce09eaef0fb464dbfe77553fcc708fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CaptumInsights(insights_config={'classes': ['Non-melanoma', 'Melanoma'], 'methods': ['Deconvolution', 'Deep Liâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95dcdaaf04a34243aedfc346f528dc92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!pip install ipywidgets\n",
    "#!jupyter nbextension enable --py widgetsnbextension\n",
    "visualizer.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fetch data and view Captum Insights at http://localhost:34931/\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "34931"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualizer.serve(debug=True, port=6006)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
